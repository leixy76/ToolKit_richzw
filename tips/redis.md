
- 为什么需要主从复制？
  - 引入从库虽然导致了数据冗余，但是能够保证数据有异地备份，还能够在故障中快速恢复，能进行读写分离等
- 简述 Redis 的主从复制过程
  - 主从复制的发起者是 slave 节点，而不是 master 节点. 主从复制是推模型
  - 全量复制, 2.8 版本之前都是「全量复制」，具体流程是类似于 RDB 持久化的流程，slave 节点发送 psync 命令后 master 生成 RDB 文件，使用一个缓冲区记录之后的命令。
  - 部分复制,主要有三个关键概念，offset、copybuffer、runid
    - offset 是偏移量，
    - copybuffer 是复制积压缓冲区，每次主节点同步数据推自己的 offset 和 buffer 过来后比对双方数据的 offset，之后决定是否需要同步 buffer 里面的数据。
    -  runid 是每个 slave 节点启动时发给 master 节点，用于标识之前是否同步过，决定进行全量还是部分复制
  - 命令传播阶段主要有两个点，一个是同步增量数据，一个是主从之间发送心跳确认双方在线，slave 节点还会去发送自己的 offset 去获取更新命令
- AOF 重写的触发条件
  - 用户手动触发 bgrewriteaof
  - aof 文件大于阈值
  - aof 文件增长比例超过设置阈值
- 为什么哈希槽的槽数是 16384（2^14）
  - 哈希槽是在 redis 集群模式中用于数据分片的功能，redis 的一致性哈希算法是用了 CRC-16，最多可以哈希到 2^16 也就是可以支持 6W 左右的哈希槽，但是最后只设置了 1W6 左右的哈希槽
  - 心跳包可能会太大导致网络阻塞。redis 集群是使用 gossip 流言协议. 假设槽位设置到了最大，如果一个节点刚好都用到了这些槽位，会导致心跳包达到了 8K，在集群内如果进行传播会导致网络阻塞
  - 集群总节点数在大多数场景不会超过 1K个
  - 提高 gossip 流言协议的传播效率。每个节点都会保存自己用到的哈希槽的 bitmap，在基于流言协议大范围传播节点信息时，会「哈希槽/节点数」的压缩，如果槽位很多的话压缩比率就高，传播节点信息的效率就会高起来
- [Redis 为什么用跳表，而不用平衡树](https://mp.weixin.qq.com/s/c4KjLtZYBVNDTmrjyizVZA)
  - 跳表
    - zset 结构体里有两个数据结构：一个是跳表，一个是哈希表。这样的好处是既能进行高效的范围查询，也能进行高效单点查询。
    - 跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表，这样的好处是能快读定位数据。
    - 跳表在创建节点的时候，随机生成每个节点的层数. 
      - 跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。
      - 这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。
  - 为什么用跳表而不用平衡树
    - 它们不是非常内存密集型的。基本上由你决定。改变关于节点具有给定级别数的概率的参数将使其比 btree 占用更少的内存。
    - Zset 经常需要执行 ZRANGE 或 ZREVRANGE 的命令，即作为链表遍历跳表。通过此操作，跳表的缓存局部性至少与其他类型的平衡树一样好。
    - 它们更易于实现、调试等。例如，由于跳表的简单性，我收到了一个补丁（已经在Redis master中），其中扩展了跳表，在 O(log(N) 中实现了 ZRANK。它只需要对代码进行少量修改。
    - 从内存占用上来比较，跳表比平衡树更灵活一些。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。
    - 在做范围查找的时候，跳表比平衡树操作要简单。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。
    - 从算法实现难度上来比较，跳表比平衡树要简单得多。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速。
- [Redis 突然变慢了如何排查并解决](https://mp.weixin.qq.com/s/-tcADbKihrfRBzMjl96Q2Q)
  - Redis 性能出问题了么
    - 正常情况下 Redis 处理的时间极短，在微秒级别。有的硬件配置比较高，当延迟 0.6ms，我们可能就认定变慢了。硬件比较差的可能 3 ms 我们才认为出现问题
    - 当你发现 Redis 运行时时的延迟是基线性能的 2 倍以上，就可以判定 Redis 性能变慢了
      - 延迟基线测量
        - redis-cli 命令提供了`–intrinsic-latency `选项，用来监测和统计测试期间内的最大延迟（以毫秒为单位），这个延迟可以作为 Redis 的基线性能
        - `redis-cli --intrinsic-latency 100` 参数100是测试将执行的秒数。我们运行测试的时间越长，我们就越有可能发现延迟峰值。 通常运行 100 秒通常是合适的，足以发现延迟问题了，当然我们可以选择不同时间运行几次，避免误差。
    - 慢指令监控
      - 使用 Redis 慢日志功能查出慢命令
        - slowlog 命令可以让我们快速定位到那些超出指定执行时间的慢命令，默认情况下命令若是执行时间超过 10ms 就会被记录到日志 slowlog 只会记录其命令执行的时间，不包含 io 往返操作，也不记录单由网络延迟引起的响应慢。
        - 我们可以根据基线性能来自定义慢命令的标准（配置成基线性能最大延迟的 2 倍），调整触发记录慢命令的阈值。 `redis-cli CONFIG SET slowlog-log-slower-than 6000`
        - 只需要查看最后 2 个慢命令，输入 slowlog get 2 即可
      - latency-monitor（延迟监控）工具。
        - Redis 在 2.8.13 版本引入了 Latency Monitoring 功能，用于以秒为粒度监控各种事件的发生频率启用延迟监视器的第一步是设置延迟阈值(单位毫秒)
        - `CONFIG SET latency-monitor-threshold 9`
  - 如何解决 Redis 变慢
    - 网络通信导致的延迟 - 需要 pipeline 来解决这个问题
    - Fork 生成 RDB 导致的延迟
      - 生成 RDB 快照，Redis 必须 fork 后台进程。fork 操作（在主线程中运行）本身会导致延迟。 Redis 使用操作系统的多进程写时复制技术 COW(Copy On Write) 来实现快照持久化，减少内存占用。
      - 从库加载 RDB 期间无法提供读写服务，所以主库的数据量大小控制在 2~4G 左右，让从库快速的加载完成。
    - 内存大页（transparent huge pages）
      - 采用了内存大页，生成 RDB 期间，即使客户端修改的数据只有 50B 的数据，Redis 需要复制 2MB 的大页。当写的指令比较多的时候就会导致大量的拷贝，导致性能变慢
    - swap：操作系统分页
      - 内存 swap 是操作系统里将内存数据在内存和磁盘间来回换入和换出的机制，涉及到磁盘的读写。
      - 触发 swap 的情况有哪些呢
        - Redis 使用了比可用内存更多的内存；
        - 与 Redis 在同一机器运行的其他进程在执行大量的文件读写 I/O 操作（包括生成大文件的 RDB 文件和 AOF 后台线程），文件读写占用内存，导致 Redis 获得的内存减少，触发了 swap。
- [Redis 内存优化神技，小内存保存大数据](https://mp.weixin.qq.com/s/rqOuadayzFwmThnPApx7SQ)
  - Redis 如何存储键值对
    - Redis 使用「dict」结构来保存所有的键值对（key-value）数据，这是一个全局哈希表，所以对 key 的查询能以 O(1) 时间得到。
    - ![img.png](redis_global_object.png)
  - 键值对优化
    - 优化神技：降低 Redis 内存使用的最粗暴的方式就是缩减键（key）与值（value）的长度。
      - 对于 key 的优化：使用单词简写方式优化内存占用。
      - value 的优化
        - 过滤不必要的数据：不要大而全的一股脑将所有信息保存，想办法去掉一些不必要的属性
        - 精简数据：比如用户的会员类型：0 表示「屌丝」、1 表示 「VIP」、2表示「VVIP」
        - 数据压缩：对数据的内容进行压缩，比如使用 GZIP、Snappy
        - 使用性能好，内存占用小的序列化方式
  - 小数据集合编码优化
    - ![img.png](redis_type_encoding.png)
    - 数据编码优化技巧
      - ziplist 的不足 - 每次修改都可能触发 realloc 和 memcopy, 可能导致连锁更新(数据可能需要挪动)。
      - quicklist 是 ziplist 和 linkedlist 的混合体，它将 linkedlist 按段切分，每一段使用 ziplist 来紧凑存储，多个 ziplist 之间使用双向指针串接起来。
    - 对象共享池
      - Redis 在启动的时候默认生成一个 0 ~9999 的整数对象共享池用于对象复用，减少内存占用。
    - 使用 Bit 比特位或 byte 级别操作
      - 比如在一些「二值状态统计」的场景下使用 Bitmap 实现，
      - 对于网页 UV 使用 HyperLogLog 来实现，大大减少内存占用。
    - 妙用 Hash 类型优化
      - 比如说系统中有一个用户对象，我们不需要为一个用户的昵称、姓名、邮箱、地址等单独设置一个 key，而是将这个信息存放在一个哈希表里。
      - 当我们为每个属性都创建 key，就会创建大量的 redisObejct 对象占用内存
- [Redis网络编程](https://mp.weixin.qq.com/s/f0muafMRbGyiRXl1O0k5ww)
  - Redis 有多快
    - 在一台普通硬件配置的 Linux 机器上跑单个 Redis 实例，处理简单命令（时间复杂度 O(N) 或者 O(log(N))），QPS 可以达到 8w+，而如果使用 pipeline 批处理功能，则 QPS 至高能达到 100w
  - Redis 为什么快
    - C 语言实现，虽然 C 对 Redis 的性能有助力，但语言并不是最核心因素。
    - 纯内存 I/O，相较于其他基于磁盘的 DB，Redis 的纯内存操作有着天然的性能优势。
    - I/O 多路复用，基于 epoll/select/kqueue 等 I/O 多路复用技术，实现高吞吐的网络 I/O。
    - 单线程模型，单线程无法利用多核，但是从另一个层面来说则避免了多线程频繁上下文切换，以及同步机制如锁带来的开销。
  - Redis 为何选择单线程
    - 对于一个 DB 来说，CPU 通常不会是瓶颈，因为大多数请求不会是 CPU 密集型的，而是 I/O 密集型。具体到 Redis 的话，如果不考虑 RDB/AOF 等持久化方案，Redis 是完全的纯内存操作，执行速度是非常快的，因此这部分操作通常不会是性能瓶颈，Redis 真正的性能瓶颈在于网络 I/O，也就是客户端和服务端之间的网络传输延迟，因此 Redis 选择了单线程的 I/O 多路复用来实现它的核心网络模型。
    - 避免过多的上下文切换开销
      - 多线程调度过程中必然需要在 CPU 之间切换线程上下文 context，而上下文的切换又涉及程序计数器、堆栈指针和程序状态字等一系列的寄存器置换、程序堆栈重置甚至是高速缓存、TLB 快表的汰换，如果是进程内的多线程切换还好一些，因为单一进程内多线程共享进程地址空间，因此线程上下文比之进程上下文要小得多，如果是跨进程调度，则需要切换掉整个进程地址空间。
    - 避免同步机制的开销
      - 如果 Redis 选择多线程模型，又因为 Redis 是一个数据库，那么势必涉及到底层数据同步的问题，则必然会引入某些同步机制，比如锁，而我们知道 Redis 不仅仅提供了简单的 key-value 数据结构，还有 list、set 和 hash 等等其他丰富的数据结构，而不同的数据结构对同步访问的加锁粒度又不尽相同，可能会导致在操作数据过程中带来很多加锁解锁的开销，增加程序复杂度的同时还会降低性能。
    - 简单可维护
  - Redis 真的是单线程
    - Preclude
      - Redis v4.0（引入多线程处理异步任务）
      - Redis v6.0（正式在网络模型中实现 I/O 多线程）
    - 单线程事件循环
      - 从 Redis 的 v1.0 到 v6.0 版本之前，Redis 的核心网络模型一直是一个典型的单 Reactor 模型：利用 epoll/select/kqueue 等多路复用技术，在单线程的事件循环中不断去处理事件（客户端请求），最后回写响应数据到客户端：
    - 多线程异步任务
      - 在 Redis v4.0 之后增加了一些的非阻塞命令如 UNLINK、FLUSHALL ASYNC、FLUSHDB ASYNC
      - UNLINK 命令其实就是 DEL 的异步版本，它不会同步删除数据，而只是把 key 从 keyspace 中暂时移除掉，然后将任务添加到一个异步队列，最后由后台线程去删除，不过这里需要考虑一种情况是如果用 UNLINK 去删除一个很小的 key，用异步的方式去做反而开销更大，所以它会先计算一个开销的阀值，只有当这个值大于 64 才会使用异步的方式去删除 key，对于基本的数据类型如 List、Set、Hash 这些，阀值就是其中存储的对象数量。
    - Redis 多线程网络模型
      - Multiple Reactors
        - 区别于单 Reactor 模式，这种模式不再是单线程的事件循环，而是有多个线程（Sub Reactors）各自维护一个独立的事件循环，由 Main Reactor 负责接收新连接并分发给 Sub Reactors 去独立处理，最后 Sub Reactors 回写响应给客户端。
        - Multiple Reactors 模式通常也可以等同于 Master-Workers 模式，比如 Nginx 和 Memcached 等就是采用这种多线程模型，虽然不同的项目实现细节略有区别，但总体来说模式是一致的。
      - ![img.png](redis_io_multiple_thread_model.png)
      - 这里大部分逻辑和之前的单线程模型是一致的，变动的地方仅仅是把读取客户端请求命令和回写响应数据的逻辑异步化了，交给 I/O 线程去完成，这里需要特别注意的一点是：I/O 线程仅仅是读取和解析客户端命令而不会真正去执行命令，客户端命令的执行最终还是要回到主线程上完成。









