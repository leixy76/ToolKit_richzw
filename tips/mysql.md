
- order by
  - 常规排序
    - explain结果  using index condition; using filesort
    - ![img.png](mysql_orderby_sort_buffer.png)
    - 上述流程只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的
  - rowid排序
    - max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法
    - ![img.png](mysql_orderby_recalltable.png)
    - rowid排序多了一步回表操作
  - order by都需要排序？
    - explain结果 using index condition
    - ![img.png](mysql_orderby.png)
    - 这个查询过程不需要临时表，也不需要排序
  - 覆盖索引
    - explain结果 using index
    - Extra 字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多
- [SQL 优化大全](https://mp.weixin.qq.com/s/Uvm_p5YuH3E8snDGnE8QLQ)
  - MySQL的基本架构
    - 查询数据库的引擎
      ```sql
      show engines;
      show variables like “%storage_engine%”;
      ```
  - SQL优化
    - SQL优化—主要就是优化索引
      - 索引的弊端
        - 当数据量很大的时候，索引也会很大(当然相比于源表来说，还是相当小的)，也需要存放在内存/硬盘中(通常存放在硬盘中)，占据一定的内存空间/物理空间。
        - 索引并不适用于所有情况：a.少量数据；b.频繁进行改动的字段，不适合做索引；c.很少使用的字段，不需要加索引；
        - a索引会提高数据查询效率，但是会降低“增、删、改”的效率。当不使用索引的时候，我们进行数据的增删改，只需要操作源表即可，但是当我们添加索引后，不仅需要修改源表，也需要再次修改索引，很麻烦。尽管是这样，添加索引还是很划算的，因为我们大多数使用的就是查询，“查询”对于程序的性能影响是很大的。
      - 索引的优势
        - 提高查询效率(降低了IO使用率)。当创建了索引后，查询次数减少了。
        - 降低CPU使用率。比如说【…order by age desc】这样一个操作，当不加索引，会把源表加载到内存中做一个排序操作，极大的消耗了资源。但是使用了索引以后，第一索引本身就小一些，第二索引本身就是排好序的，左边数据最小，右边数据最大。
    - explain执行计划常用关键字详解
      - id
        - id值相同，从上往下顺序执行。表的执行顺序因表数量的改变而改变。
        - id值不同，id值越大越优先查询。这是由于在进行嵌套子查询时，先查内层，再查外层。
      - select_type关键字的使用说明：查询类型
        - simple：简单查询 不包含子查询，不包含union查询。
        - primary：包含子查询的主查询(最外层)
        - subquery：包含子查询的主查询(非最外层)
        - derived：衍生查询(用到了临时表)
        - union：union之后的表称之为union表，如上例
        - union result：告诉我们，哪些表之间使用了union查询
      - type关键字的使用说明：索引类型
        - system、const只是理想状况，实际上只能优化到index --> range --> ref这个级别。要对type进行优化的前提是，你得创建索引。
        - system - 源表只有一条数据(实际中，基本不可能)； 衍生表只有一条数据的主查询(偶尔可以达到)
        - const - 仅仅能查到一条数据的SQL ,仅针对Primary key或unique索引类型有效。
        - eq_ref - 唯一性索引，对于每个索引键的查询，返回匹配唯一行数据（有且只有1个，不能多 、不能0），并且查询结果和数据条数必须一致。此种情况常见于唯一索引和主键索引。
        - ref - 非唯一性索引，对于每个索引键的查询，返回匹配的所有行（可以0，可以1，可以多）
        - range - 检索指定范围的行 ,where后面是一个范围查询(between, >, <, >=, in) in有时候会失效，从而转为无索引时候的ALL
        - index - 查询全部索引中的数据(扫描整个索引)
        - ALL - 查询全部源表中的数据(暴力扫描全表)
      - possible_keys和key
        - possible_keys可能用到的索引。是一种预测，不准。了解一下就好。
        - key指的是实际使用的索引。
      - key_len: 索引的长度，用于判断复合索引是否被完全使用(a,b,c)。
      - ref - 这里的ref的作用，指明当前表所参照的字段。
        - 注意与type中的ref值区分。在type中，ref只是type类型的一种选项值。
      - rows: 被索引优化查询的数据个数
      - extra
        - using filesort：针对单索引的情况 - 表示你当前的SQL性能消耗较大。表示进行了一次“额外”的排序。常见于order by语句中。
          - 对于单索引，如果排序和查找是同一个字段，则不会出现using filesort；如果排序和查找不是同一个字段，则会出现using filesort；因此where哪些字段，就order by哪些些字段。
        - using temporary: 当出现了这个词，也表示你当前的SQL性能消耗较大。这是由于当前SQL用到了临时表。一般出现在group by中。
        - using index: “索引覆盖”就表示不用读取源表，而只利用索引获取数据，不需要回源表查询
        - using where: 表示需要【回表查询】，表示既在索引中进行了查询，又回到了源表进行了查询。
        - impossible where: 当where子句永远为False的时候，会出现impossible where
    - 优化示例
      - 复合索引顺序和使用顺序一致。对于复合索引，不要跨列使用
      - 索引需要逐步优化(每次创建新索引，根据情况需要删除以前的废弃索引)
      - 使用了in有时候会导致索引失效，将含In的范围查询，放到where条件的最后，防止失效。
      - 对于两张表，索引往哪里加？答：对于表连接，小表驱动大表。索引建立在经常使用的字段上。
      - 一般情况下，左连接给左表加索引。右连接给右表加索引。其他表需不需要加索引，我们逐步尝试。
      - 不要在索引上进行任何操作(计算、函数、类型转换)，否则索引失效
      - 索引不能使用不等于（!= <>）或is null (is not null)，否则自身以及右侧所有全部失效(针对大多数情况)。复合索引中如果有>，则自身和右侧索引全部失效。
      - exists和in的优化
        - 如果主查询的数据集大，则使用in关键字，效率高。
        - 如果子查询的数据集大，则使用exist关键字,效率高。
- [事务会发生死锁?](https://mp.weixin.qq.com/s/DnCc5NIrMzvJuTF_xN6RYQ)
  - ![img.png](mysql_tran_question.png)
  - ![img.png](mysql_tran_step.png)
  - 为什么会发生死锁
    - 我们可以通过 select * from performance_schema.data_locks\G; 这条语句，查看事务执行 SQL 过程中加了什么锁
    - Time 1 阶段加锁分析
      - 可以看到，共加了两个锁，分别是：
        - 表锁：X 类型的意向锁；
        - 行锁：X 类型的间隙锁；
      - LOCK_TYPE 中的 RECORD 表示行级锁，而不是记录锁的意思，通过 LOCK_MODE 可以确认是 next-key 锁，还是间隙锁，还是记录锁：
        - 如果 LOCK_MODE 为 X，说明是 next-key 锁；
        - 如果 LOCK_MODE 为 X, REC_NOT_GAP，说明是记录锁；
        - 如果 LOCK_MODE 为 X, GAP，说明是间隙锁；
      - 此时事务 A 在主键索引（INDEX_NAME : PRIMARY）上加的是间隙锁，锁范围是(20, 30)。
    - Time 2 阶段加锁分析
      - 事务 B 在主键索引（INDEX_NAME : PRIMARY）上加的是间隙锁，锁范围是(20, 30)。
    - 事务 A 和 事务 B 的间隙锁范围都是一样的，为什么不会冲突？
      - 两个事务的间隙锁之间是相互兼容的，不会产生冲突
      - 间隙锁的意义只在于阻止区间被插入，因此是可以共存的。一个事务获取的间隙锁不会阻止另一个事务获取同一个间隙范围的间隙锁，共享和排他的间隙锁是没有区别的，他们相互不冲突，且功能相同。
    - Time 3 阶段加锁分析
      - 事务 A 的状态为等待状态（LOCK_STATUS: WAITING），因为向事务 B 生成的间隙锁（范围 (20, 30)）中插入了一条记录，所以事务 A 的插入操作生成了一个插入意向锁（LOCK_MODE:INSERT_INTENTION）
      - 插入意向锁是什么？
        - 插入意向锁名字里虽然有意向锁这三个字，但是它并不是意向锁，它属于行级锁，是一种特殊的间隙锁。但不同于间隙锁的是，该锁只用于并发插入操作。
        - 如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。
        - 尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。所以，插入意向锁和间隙锁之间是冲突的。
        - 插入意向锁的生成时机：
          - 每插入一条新记录，都需要看一下待插入记录的下一条记录上是否已经被加了间隙锁，如果已加间隙锁，那 Insert 语句会被阻塞，并生成一个插入意向锁 
    - Time 4 阶段加锁分析
      - 事务 B 在生成插入意向锁时而导致被阻塞，这是因为事务 B 向事务 A 生成的间隙锁（范围 (20, 30)）中插入了一条记录，而插入意向锁和间隙锁是冲突的，所以事务  B 在获取插入意向锁时就陷入了等待状态。
  - 本次案例中，事务 A 和事务 B 在执行完后 update 语句后都持有范围为(20, 30）的间隙锁，而接下来的插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，满足了死锁的四个条件：互斥、占有且等待、不可强占用、循环等待，因此发生了死锁。
- [幻读是怎么被解决的](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247498122&idx=2&sn=f2062523af7e977a6deebe4d8be4501a&chksm=f98dbd20cefa3436c4b1e0b29d1f0a4d9ddc64cf7917a10b5d99f65db41b1427ea503ba1a45f&scene=178&cur_album_id=1955634887135199237#rd)
  - 在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。
  - 幻读仅专指“新插入的行”，中途通过 update 更新数据而出现同一个事务前后两次查询的「结果集合」不一样，这种不算幻读。
  - 这个幻读例子不是已经被「可重复读」隔离级别解决了吗？为什么还要有 next-key 呢？
    - 要讨论「可重复读」隔离级别的幻读现象，是要建立在「当前读」的情况下。select ... for update 这种查询语句是当前读，每次执行的时候都是读取最新的数据
    - Innodb 引擎为了解决「可重复读」隔离级别使用「当前读」而造成的幻读问题，就引出了 next-key 锁，就是记录锁和间隙锁的组合
      - 记录锁，锁的是记录本身；
      - 间隙锁，锁的就是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读现象。
    - next-key 锁的加锁规则其实挺复杂的，在一些场景下会退化成记录锁或间隙锁
    - 注意的是，next-key lock 锁的是索引，而不是数据本身，所以如果 update 语句的 where 条件没有用到索引列，那么就会全表扫描，在一行行扫描的过程中，不仅给行加上了行锁，还给行两边的空隙也加上了间隙锁，相当于锁住整个表，然后直到事务结束才会释放锁。
    - 在线上千万不要执行没有带索引条件的 update 语句，不然会造成业务停滞
- [MySQL的锁](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247496932&idx=1&sn=5bd840a32040998aa60c6317ccad71ac&chksm=f98db04ecefa39584c87d1b514b6f607e0950af514b67d8299e12049907cdb11fecfc02bc374&scene=21#wechat_redirect)
  - 全局锁
    - 要使用全局锁，则要执行 `flush tables with read lock`
      - 整个数据库就处于只读状态了，这时其他线程执行以下操作，都会被阻塞: 对数据的增删查改操作/对表结构的更改操作
    - 如果要释放全局锁，则要执行 `unlock tables` / 当会话断开了，全局锁会被自动释放
    - 全局锁应用场景是什么 - 主要应用于做全库逻辑备份
    - 既然备份数据库数据的时候，使用全局锁会影响业务，那有什么其他方式可以避免
      - 如果数据库的引擎支持的事务支持可重复读的隔离级别，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。
      - 在使用 mysqldump 时加上 –single-transaction 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎
  - 表级锁
    - 表锁 
      - `lock tables t_student read\write;`
      - 表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。
    - 元数据锁 MDL
      - 我们不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：
        - 对一张表进行 CRUD 操作时，加的是 MDL 读锁；
        - 对一张表做结构变更操作的时候，加的是 MDL 写锁；
      - MDL 是在事务提交后才会释放，这意味着事务执行期间，MDL 是一直持有的。- 长事务不利的原因
      - 为什么线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞？
        - 因为申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。
        - 所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。
    - 意向锁
      - 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；
      - 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；
      - 也就是，当执行插入、更新、删除操作，需要先对表加上「意向共享锁」，然后对该记录加独占锁。
      - 普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的。
      - select 也是可以对记录加共享锁和独占锁的
        - //先在表上加上意向共享锁，然后对读取的记录加独占锁 select ... lock in share mode;
        - //先表上加上意向独占锁，然后对读取的记录加独占锁 select ... for update;
      - 意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables … read）和独占表锁（lock tables … write）发生冲突。
      - 如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。意向锁的目的是为了快速判断表里是否有记录被加锁。
    - AUTO-INC 锁
      - 为某个字段声明 AUTO_INCREMENT 属性时，之后可以在插入数据时，可以不指定该字段的值，数据库会自动给该字段赋值递增的值，这主要是通过 AUTO-INC 锁实现的。
      - AUTO-INC 锁是特殊的表锁机制，锁不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放。
      - 在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种轻量级的锁来实现自增。会为被 AUTO_INCREMENT 修饰的字段加上轻量级锁，然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁。
      - InnoDB 存储引擎提供了个 innodb_autoinc_lock_mode 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。当 innodb_autoinc_lock_mode = 2 是性能最高的方式，但是会带来一定的问题。因为并发插入的存在，在每次插入时，自增长的值可能不是连续的，这在有主从赋值的场景中是不安全的。
  - 行级锁
    - Record Lock，记录锁，也就是仅仅把一条记录锁上；
    - Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；
    - Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。
- [明明加了唯一索引，为什么还是产生重复数据](https://mp.weixin.qq.com/s/Jdi4GS1SqtUs7U1FWBkwxw)
  - 在mysql8的一张innodb引擎的表中，加了唯一索引，但最后发现数据竟然还是重复了
  - 唯一索引字段包含null
    - 创建唯一索引的字段，都不能允许为null，否则mysql的唯一性约束可能会失效。
  - 逻辑删除表加唯一索引
    - 物理删除 - 用delete语句操作
    - 逻辑删除 - 主要是通过update语句操作的
    - 对于这种逻辑删除的表，是没法加唯一索引的 - 假设之前给商品表中的name和model加了唯一索引，如果用户把某条记录删除了，delete_status设置成1了。后来，该用户发现不对，又重新添加了一模一样的商品。
    - 方案
      - 删除状态+1 
      - 增加时间戳字段
        - 在添加数据时，timeStamp字段写入默认值1。
        - 然后一旦有逻辑删除操作，则自动往该字段写入时间戳。 这样即使是同一条记录，逻辑删除多次，每次生成的时间戳也不一样，也能保证数据的唯一性。
      - 增加id字段
        - 增加时间戳字段基本可以解决问题。但在在极限的情况下，可能还是会产生重复数据。
        - 该方案的思路跟增加时间戳字段一致，即在添加数据时给delete_id设置默认值1，然后在逻辑删除时，给delete_id赋值成当前记录的主键id。
  - 重复历史数据如何加唯一索引
    - 最简单的做法是，增加一张防重表，然后把数据初始化进去。
      ```sql
      insert into product_unqiue(id,name,category_id,unit_id,model) 
      select max(id), select name,category_id,unit_id,model from product
      group by name,category_id,unit_id,model;
      ```
    - 增加一个delete_id字段
      - 表创建唯一索引之前，先要做数据处理。 
        - 获取相同记录的最大id：然后将delete_id字段设置成1
        - 然后将其他的相同记录的delete_id字段，设置成当前的主键
  - 给大字段加唯一索引
    - 如果model字段很大，这样就会导致该唯一索引，可能会占用较多存储空间 - 目前mysql innodb存储引擎中索引允许的最大长度是3072 bytes，其中unqiue key最大长度是1000 bytes
    - 增加hash字段
      - 我们可以增加一个hash字段，取大字段的hash值，生成一个较短的新值。该值可以通过一些hash算法生成，固定长度16位或者32位等。
    - 加唯一索引
      - 如果实在不好加唯一索引，就不加唯一索引，通过其他技术手段保证唯一性。
    - redis分布式锁 - 用name、model、delete_status和delete_id字段，生成一个hash值，然后给这个新值加锁








