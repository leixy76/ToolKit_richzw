
- [优化 Milvus 性能](https://mp.weixin.qq.com/s/4gDsAF4QnmXWzomrSFRLLg)
    - Milvus 是读写分离且无状态的向量数据库，状态信息储存在 etcd 中，coordinator 节点去 etcd 请求状态并修改状态
        - 当用户需要查看状态信息、清理状态信息场景时，etcd 调试工具必不可少。
        - [BirdWatcher  是 Milvus 2.0 项目的调试工具，该工具连接 etcd 并检查 Milvus 系统的某些状态](https://mp.weixin.qq.com/s/ot-eMCKqM7aP5pEbGaMIQA)
    - Milvus 单机
        - 在单机模式下，milvus内置一个rocksdb用于代替pulsar的功能，rdb_data目录里的东西是rockdb管理的，所有insert/delete/upsert的数据都会先在rocksdb里存一份做为write ahead log，然后querynode datanode从rocksdb里把数据拉出来消费
        - 如果rocksdb里的数据消费完了，不会立刻删除，因为rocksdb有自己的gc，只不过这些数据对milvus来说已经消费过了，放着只是为了保证数据安全性，一旦milvus崩了，再启动的时候，那些没被持久化到minio里的数据还能从rocksdb里拉回来
    - 合理的预计数据量，表数目大小，QPS 参数等指标
    - 选择合适的索引类型和参数
        - 索引的选择对于向量召回的性能至关重要，Milvus 支持了 Annoy，Faiss，HNSW，DiskANN 等多种不同的索引，用户可以根据对延迟、内存使用和召回率的需求进行选择
        - 是否需要精确结果？
            - 只有 Faiss 的 Flat 索引支持精确结果，但需要注意 Flat 索引检索速度很慢，查询性能通常比其他 Milvus 支持的索引类型低两个数量级以上，因此只适合千万级数据量的小查询
        - 数据量是否能加载进内存？
            - 对于大数据量，内存不足的场景，Milvus 提供两种解决方案：
                - DiskANN
                    - DiskANN 依赖高性能的磁盘索引，借助 NVMe 磁盘缓存全量数据，在内存中只存储了量化后的数据。
                    - DiskANN 适用于对于查询 Recall 要求较高，QPS 不高的场景。
        - 构建索引和内存资源是否充足
            - 性能优先，选择 HNSW 索引
- [Milvus 2.0 数据插入与持久化](https://mp.weixin.qq.com/s/D0xdD9mqDgxFvNY19hvDgQ)
    - 删数据逻辑
        - 调用delete删除一条已存在的数据时，它只是在某个segment里把某条数据标记为deleted，但是这个segment的数据此时仍然是一个整体，那条被删的数在内存里仍然占着空间。
        - 当你又调用insert增加一条数据时，这条新数据实际上是放入一个新的segment中，这条新数据也会占用额外内存空间。因此，随着你继续删除+insert，你会看到内存用量增加，新的这个segment执行的是暴搜，cpu用量会增加。
        - 随着新的segment中的数据达到一定量可以建索引了，indexnode就开始给这个新segment建索引，建索引就会消耗cpu。只有当某个segment中被删的数据达到20%以上，datanode开始对这个segment进行compact，
        - 把deleted的数据去除掉，剩下的数据存为一个新的segmemt。在compact之后有可能会发生小segment合并成大segment。总之，删除和更新数据会产生很多额外的工作，消耗内存消耗cpu，设计上就如此
    - 如果用num_enrtities观察行数的话，是看不出变化的，因为num_entities不统计被删除的行数。如果你是删除之后再用query去查询主键，还能查到的话，那八成是因为你是删完就立即query，而consistency_level没有设为Strong
- [动态 Schema](https://mp.weixin.qq.com/s/jhyePhxjUbWBicEvqxIKGQ)
  - Milvus 如何实现动态 Schema 功能
    - Milvus 通过用隐藏的元数据列的方式，来支持用户为每行数据添加不同名称和数据类型的动态字段的功能。
    - 当用户创建表并开启动态字段时，Milvus 会在表的 Schema 里创建一个名为$meta的隐藏列。JSON 是一种不依赖语言的数据格式，被现代编程语言广泛支持，因此 Milvus 隐藏的动态实际列使用 JSON 作为数据类型。
  - 动态 Schema 的 A、B 面
    - 一方面，动态 Schema 设置简便，无需复杂的配置即可开启动态 Schema；动态 Schema 可以随时适应数据模型的变化，开发者无需进行重构或调整代码。
    - 另一方面，使用动态 Schema 进行过滤搜索比固定 Schema 慢得多；在动态 Schema 上进行批量插入比较复杂，推荐用户使用行式插入接口写入动态字段数据。
- [向量数据库](https://developer.aliyun.com/article/1328709?spm=a2c6h.12883283.index.43.5ba74307ZagBs5)
    - 本质上就是给定一条向量，我们要搜索离它最近的 k 条向量，那最近的这个距离的定义可以是，比如说，内积或者欧氏距离、或者余弦距离。有了距离的定义以后，我们还要定义一些向量的搜索算法。
    - 向量搜索算法总体来说分为两类，
        - 第一类是精准搜索 KNN - FLAT，一个向量一个向量地去检索，然后取 top k，召回率会很高，但是它的执行的性能会比较差，因为要做全局扫描
        - approximate nearest neighbor，就是 ANN，那这类算法它可能回答的并不是最精准的 top k 的向量，但是这一类算法的好处是执行效率比较高。
- 海量数据相似数据查找方法
    - 高维稀疏向量和稠密向量两大方向
        - 高维稀疏向量的相似查找 - minhash, lsh(Locality-Sensitive Hashing）, simhash
            - minhash
                - 定义一个函数h：计算集合S最小的minhash值，就是在这种顺序下最先出现1的元素
                - 如果进行n次重排的话，就会有n个minhash函数，{h1(S), h2(S)…, hn(S)}, 那原来每个高维集合，就会被降到n维空间，比如S1->{h1(S1), h2(S1)…, hn(S1)}
                - 实际中因为重排比较耗时，会用若干随机哈希函数替代. 同样可以定义n个哈希函数【不需要重排，每个hash计算对应的值就行】，进行上述操作，那每个集合S就被降维到n维空间的签名。
            - LSH
                - minhash解决了高维向量间计算复杂度问题(通过minhash 机制把高维降低到n维低纬空间)
                - 但是还没解决一个问题：两两比较，时间复杂度O(n^2)
                - LSH 就是这样的机制，通过哈希机制，让相似向量尽可能出现一个桶中，而不相似的向量出现在不同的桶中. 相似度计算只在么个桶中进行，每个桶彼此之间不做相似度计算。
                - 在minhashing 签名的基础上做LSH
                    - 一个高维向量通过minhashing处理后变成n维低维向量的签名，现在把这n维签名分成b组，每组r个元素。
                    - 每组通过一个哈希函数，把这组的r个元素组成r维向量哈希到一个桶中。
                    - 每组可以使用同一个哈希函数，但是每组桶没交集，即使哈希值一样。桶名可以类似：组名+哈希值。
                    - 在一个桶中的向量才进行相似度计算，相似度计算的向量是minhash的n维向量（不是r维向量）。
            - simHash
                - Simhash技术引入到海量文本去重领域
                - google 通过Simhash把一篇文本映射成64bits的二进制串。
                    - 文档每个词有个权重。
                    - 文档每个词哈希成一个二进制串。
                    - 文档最终的签名是各个词和签名的加权和(如果该位是1则+weight，如果是0，则-weight)，再求签名[>0则变成1，反之变成0]得到一个64位二进制数。
                    - 如果两篇文档相同，则他们simhash签名汉明距离小于等于3。
                - 因为simhash本质上是局部敏感hash，所以可以使用海明距离来衡量simhash值的相似度。
                - 假设我们要寻找海明距离3以内的数值，根据抽屉原理，只要我们将整个64位的二进制串划分为4块，无论如何，匹配的两个simhash code之间至少有一块区域是完全相同的。
    - 高效的搜索算法有很多，其主要思想是通过两种方式提高搜索效率：
        - 减少向量大小——通过降维或减少表示向量值的长度。
        - 缩小搜索范围——可以通过聚类或将向量组织成基于树形、图形结构来实现，并限制搜索范围仅在最接近的簇中进行，或者通过最相似的分支进行过滤。
    - ANN 最近邻检索
        - [Comprehensive Guide To Approximate Nearest Neighbors Algorithms](https://towardsdatascience.com/comprehensive-guide-to-approximate-nearest-neighbors-algorithms-8b94f057d6b6)
        - 树方法，如 KD-tree，Ball-tree，Annoy
        - 哈希方法，如 Local Sensitive Hashing (LSH)
        - 矢量量化方法，如 Product Quantization (PQ)
        - 近邻图方法，如 Hierarchical Navigable Small World (HNSW)
    - Faiss 类似 Kmeans
        - 我们可以将向量想象为包含在 Voronoi 单元格中 - 当引入一个新的查询向量时，首先测量其与质心 (centroids) 之间的距离，然后将搜索范围限制在该质心所在的单元格内。
        - 为了解决搜索时可能存在的遗漏问题，可以将搜索范围动态调整，例如当 nprobe = 1 时，只搜索最近的一个聚类中心，当 nprobe = 2 时，搜索最近的两个聚类中心，根据实际业务的需求调整 nprobe 的值。
    - Product Quantization (PQ)
        - 在大规模数据集中，聚类算法最大的问题在于内存占用太大
            - 保存每个向量的坐标，而每个坐标都是一个浮点数，占用的内存就已经非常大了。
            - 还需要维护聚类中心和每个向量的聚类中心索引，这也会占用大量的内存。
        - 对于第一个问题，可以通过量化 (Quantization) 的方式解决，也就是常见的有损压缩.例如在内存中可以将聚类中心里面每一个向量都用聚类中心的向量来表示，并维护一个所有向量到聚类中心的码本，这样就能大大减少内存的占用。
            - 但是在高维坐标系中，还会遇到维度灾难问题，具体来说，随着维度的增加，数据点之间的距离会呈指数级增长，这也就意味着，在高维坐标系中，需要更多的聚类中心点将数据点分成更小的簇，才能提高分类的质量。否者，向量和自己的聚类中心距离很远，会极大的降低搜索的速度和质量。
        - 对于第二个问题，将向量分解为多个子向量，然后对每个子向量独立进行量化，比如将 128 维的向量分为 8 个 16 维的向量，然后在 8 个 16 维的子向量上分别进行聚类，因为 16 维的子向量大概只需要 256 个聚类中心就能得到还不错的量化结果，所以就可以将码本的大小从 2^64 降低到 8 * 256 = 2048 个聚类中心，从而降低内存开销
    - Hierarchical Navigable Small Worlds (HNSW) 类似 skiplist
        - 这种方法的基本思想是每次将向量加到数据库中的时候，就先找到与它最相邻的向量，然后将它们连接起来，这样就构成了一个图。当需要搜索的时候，就可以从图中的某个节点开始，不断的进行最相邻搜索和最短路径计算，直到找到最相似的向量。
        - HNSW 继承了相同的分层格式，最高层具有更长的边缘（用于快速搜索），而较低层具有较短的边缘（用于准确搜索）
    - 相似性测量 (Similarity Measurement)
        - 欧几里得距离（Euclidean Distance）
            - 欧几里得距离算法的优点是可以反映向量的绝对距离，适用于需要考虑向量长度的相似性计算。
            - 例如推荐系统中，需要根据用户的历史行为来推荐相似的商品，这时就需要考虑用户的历史行为的数量，而不仅仅是用户的历史行为的相似度
        - 余弦相似度（Cosine Similarity）
            - 余弦相似度是指两个向量之间的夹角余弦值
            - 余弦相似度算法的优点是可以反映向量的方向，适用于不需要考虑向量长度的相似性计算。因此适用于高维向量的相似性计算。例如语义搜索和文档分类。
        - 点积相似度 (Dot product Similarity)
            - 点积相似度是指两个向量的点积，也就是两个向量对应位置的元素相乘之后再求和。点积相似度算法的优点是可以反映向量的绝对距离和方向，适用于需要考虑向量长度的相似性计算。例如推荐系统中，需要根据用户的历史行为来推荐相似的商品，这时就需要考虑用户的历史行为的数量，而不仅仅是用户的历史行为的相似度。
            - 点积相似度算法的缺点是需要对向量进行归一化，否则会受到向量长度的影响。例如在推荐系统中，如果用户的历史行为数量很多，那么用户的历史行为向量的长度就会很大，这样就会导致点积相似度算法的结果偏向于历史行为数量较少的用户。
            - 点积相似度算法的优点在于它简单易懂，计算速度快，并且兼顾了向量的长度和方向。它适用于许多实际场景，例如图像识别、语义搜索和文档分类等。但点积相似度算法对向量的长度敏感，因此在计算高维向量的相似性时可能会出现问题。
    - 过滤 (Filtering)
        - 在实际的业务场景中，往往不需要在整个向量数据库中进行相似性搜索，而是通过部分的业务字段进行过滤再进行查询。所以存储在数据库的向量往往还需要包含元数据，例如用户 ID、文档 ID 等信息。这样就可以在搜索的时候，根据元数据来过滤搜索结果，从而得到最终的结果。
        - 为此，向量数据库通常维护两个索引：一个是向量索引，另一个是元数据索引。然后，在进行相似性搜索本身之前或之后执行元数据过滤，但无论哪种情况下，都存在导致查询过程变慢的困难。
        - Pre-filtering：在向量搜索之前进行元数据过滤。虽然这可以帮助减少搜索空间，但也可能导致系统忽略与元数据筛选标准不匹配的相关结果。
        - Post-filtering：在向量搜索完成后进行元数据过滤。这可以确保考虑所有相关结果，在搜索完成后将不相关的结果进行筛选。
    - https://guangzhengli.com/blog/zh/vector-database/
- [向量检索技术](https://mp.weixin.qq.com/s/705usxBUmLcZL3rrB4Du9A)
  - 定义
    - 向量检索主要是做一个 K Nearest Neighbors (K最近邻，简称 KNN) 计算，目标是在N个D维的向量的库中找最相似的k个结果
    - KNN 计算通常代价比较大，很难在较短时间内返回结果，此外，在很多场景，用户并不需要绝对精确的相似结果
    - 通常会使用相似最近邻搜索，即 ANN 的方式来替代 KNN，从k个绝对最近似结果变成k个近似最优结果，以牺牲一定准确度的前提，得到更短的响应时间。
  - 向量检索的四种算法
    - Table-based，典型算法如 LSH
    - Tree-based，是把向量根据相似度去构造成一个树的结构
    - Cluster-based，也称为 IVF（Inverted File），把向量先进行聚类处理，检索时首先计算出最近的 k 个聚类中心，再在这些聚类中心中计算出最近的 k 个向量
    - Graph-based， 把向量按照相似度构建成一个图结构，检索变成一个图遍历的过程。常用算法是HNSW
  - ByteHouse
- [向量数据库](https://mp.weixin.qq.com/s/UCgJi7MfAnn8tAPvL3sldQ)
  - 向量检索算法
    - 基于树的方法，例如KDTree和Annoy
    - 基于图的方法，例如HNSW
    - 基于乘积量化的方法，例如SQ和PQ
    - 基于哈希的方法，例如LSH
    - 基于倒排索引的方法
    - 基于聚类 IVF
  - 数据压缩方式建立索引, 主要包括平坦压缩和量化压缩
    - 平坦压缩是指以未经修改的形式存储向量的索引，
    - 量化中索引的底层向量被分解成由较少字节组成的块（通常通过将浮点数转换为整数）以减少内存消耗和搜索过程中的计算成本。
  



























